# csv mappings
csvSchema {
  rowSize = 13
  x1 { type = double, index = 10 }
  y1 { type = double, index = 11 }
  x2 { type = double, index = 12 }
  y2 { type = double, index = 13 }
}
tiling {
  levels = [0,1,2]
  bins = 4
  source = "src/test/resources/XYSegmentJobTest/taxi_one_day.csv",
  tms = false
}
xySegment {
  arcType=fullline
  projection=cartesian
  minSegLen=4
  maxSegLen=1024
  x1Column=x1
  y1Column=y1
  x2Column=x2
  y2Column=y2
  xyBounds=[-180, -85.05112878, 180, 85.05112878]
  tileSize = 256
}
# local file output config
fileOutput {
  dest = "build/tmp/test_file_output"
  layer = segment
}
# pass-through config for spark (see http://spark.apache.org/docs/latest/configuration.html)
spark {
  master = "local"
  app.name = test
}
# pass-through config for spark-csv data loader (see https://github.com/databricks/spark-csv)
sparkCsv {
  header = "false"
}
